# ğŸš€ Projeto PySpark - Leitura, TransformaÃ§Ã£o e EDA de CSV

Projeto completo utilizando **PySpark** para leitura, limpeza, transformaÃ§Ã£o e anÃ¡lise exploratÃ³ria de grandes volumes de dados em CSV.  
Ideal para portfÃ³lio de **Engenharia e AnÃ¡lise de Dados**, com integraÃ§Ã£o de mÃºltiplas fontes e visualizaÃ§Ãµes grÃ¡ficas.

---

## ğŸ§© Objetivos do Projeto

- Ler **CSVs grandes** com o Spark (`spark.read.csv()`).
- Limpar e **normalizar colunas** (nomes, datas, valores).
- Salvar resultados em **formato Parquet** (otimizado).
- Fazer **AnÃ¡lise ExploratÃ³ria (EDA)** com PySpark e matplotlib.
- **Converter formatos** (CSV â†’ Parquet â†’ JSON).
- Medir diferenÃ§a de desempenho entre formatos.
- Fazer **joins e normalizaÃ§Ã£o** entre datasets relacionados.

---

## ğŸ—ï¸ Estrutura do Pipeline

Etapas executadas no script `src/pipeline_pyspark.py`:

| Etapa | DescriÃ§Ã£o |
|-------|------------|
| 1ï¸âƒ£ | Leitura de datasets CSV grandes |
| 2ï¸âƒ£ | Limpeza e padronizaÃ§Ã£o de colunas |
| 3ï¸âƒ£ | ConversÃ£o de tipos e remoÃ§Ã£o de duplicatas |
| 4ï¸âƒ£ | Salvamento em Parquet |
| 5ï¸âƒ£ | EDA: mÃ©dias, contagens, distribuiÃ§Ãµes |
| 6ï¸âƒ£ | VisualizaÃ§Ãµes (Top produtos, DistribuiÃ§Ã£o, EvoluÃ§Ã£o temporal) |
| 7ï¸âƒ£ | ConversÃ£o entre formatos (CSV, Parquet, JSON) |
| 8ï¸âƒ£ | JunÃ§Ã£o entre clientes, produtos e vendas |
| 9ï¸âƒ£ | Salvamento do dataset final tratado |

---

## ğŸ“Š Exemplos de VisualizaÃ§Ãµes

### ğŸ”¹ Top 10 Produtos Mais Vendidos
![Top 10 Produtos](output/top10_produtos.png)

### ğŸ”¹ DistribuiÃ§Ã£o de Valores de Venda
![DistribuiÃ§Ã£o](output/distribuicao_valor_venda.png)

### ğŸ”¹ EvoluÃ§Ã£o de Vendas no Tempo
![EvoluÃ§Ã£o de Vendas](output/evolucao_vendas.png)

---

## âš™ï¸ Tecnologias Utilizadas

- **Python 3.10+**
- **Apache Spark (PySpark)**
- **Pandas & Matplotlib**
- **Faker** (para gerar dados falsos)
- **Logging** (para registrar execuÃ§Ã£o)
- **Parquet / JSON** (armazenamento eficiente)

---

## ğŸ“¦ InstalaÃ§Ã£o

1. Clone o repositÃ³rio:
   ```bash
   git clone https://github.com/seuusuario/projeto-pyspark-eda.git
   cd projeto-pyspark-eda

Crie e ative um ambiente virtual:

python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows

Instale as dependÃªncias:

pip install -r requirements.txt

Gere os datasets:

python src/gerar_datasets.py

Execute o pipeline PySpark:

python src/pipeline_pyspark.py