{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0cdeb9-2a07-4278-929f-488c743a94b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SyntheticFraudDetection\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c6e514-8bd0-40f6-a5d7-313582ee9cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create features and prepare data\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Index categorical columns\n",
    "indexer_type = StringIndexer(inputCol=\"transaction_type\", outputCol=\"type_index\")\n",
    "indexer_country = StringIndexer(inputCol=\"country\", outputCol=\"country_index\")\n",
    "\n",
    "# OneHot encoding\n",
    "encoder = OneHotEncoder(\n",
    "    inputCols=[\"type_index\", \"country_index\"],\n",
    "    outputCols=[\"type_vec\", \"country_vec\"]\n",
    ")\n",
    "\n",
    "# Assemble features into a single vector\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"amount\", \"time_since_last_transaction\", \"type_vec\", \"country_vec\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline(stages=[indexer_type, indexer_country, encoder, assembler])\n",
    "data_prepared = pipeline.fit(data).transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43536426-1bd9-4b8f-ad6b-5ffdb1e5b9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train and test sets\n",
    "train, test = data_prepared.randomSplit([0.7, 0.3], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e1646d-06d4-4e5d-a597-b2615e5cc047",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train models\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, LogisticRegression\n",
    "\n",
    "# Decision Tree\n",
    "dt = DecisionTreeClassifier(labelCol=\"fraud\", featuresCol=\"features\")\n",
    "model_dt = dt.fit(train)\n",
    "predictions_dt = model_dt.transform(test)\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression(labelCol=\"fraud\", featuresCol=\"features\")\n",
    "model_lr = lr.fit(train)\n",
    "predictions_lr = model_lr.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1203d23-adc0-4373-82a4-5e8beb694135",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate performance\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"fraud\", metricName=\"areaUnderROC\")\n",
    "\n",
    "auc_dt = evaluator.evaluate(predictions_dt)\n",
    "auc_lr = evaluator.evaluate(predictions_lr)\n",
    "\n",
    "print(f\"AUC - Decision Tree: {auc_dt:.3f}\")\n",
    "print(f\"AUC - Logistic Regression: {auc_lr:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
