Projeto PySpark - WordCount

Contagem de palavras em arquivos de texto usando PySpark.
Inclui abordagens com RDDs, DataFrames e Streaming.
Projeto didÃ¡tico para aprendizado de processamento distribuÃ­do com Spark.

ğŸ“‚ Estrutura do Projeto
wordcount_pyspark/
â”‚
â”œâ”€â”€ texto.txt                # Arquivo de exemplo
â”œâ”€â”€ wordcount_rdd.py         # VersÃ£o RDD
â”œâ”€â”€ wordcount_dataframe.py   # VersÃ£o DataFrame
â”œâ”€â”€ wordcount_streaming.py   # VersÃ£o Streaming
â”œâ”€â”€ README.md                # Este arquivo
â”œâ”€â”€ saida/                   # Resultado da versÃ£o RDD
â””â”€â”€ saida_df/                # Resultado da versÃ£o DataFrame

âš™ï¸ PrÃ©-requisitos

Python 3.7+

PySpark instalado:

pip install pyspark


Para streaming: criar as pastas stream_input e stream_output.

1ï¸âƒ£ WordCount com RDDs

Arquivo: wordcount_rdd.py

DescriÃ§Ã£o:

LÃª arquivo de texto

Remove pontuaÃ§Ã£o e normaliza palavras

Conta a frequÃªncia de cada palavra usando RDDs

Salva resultado em arquivo e imprime no terminal

ExecuÃ§Ã£o:

python wordcount_rdd.py


Exemplo de saÃ­da:

python: 3
spark: 2
aprendizado: 1
dados: 4


SaÃ­da: salva na pasta saida/contagem_palavras.

2ï¸âƒ£ WordCount com DataFrames

Arquivo: wordcount_dataframe.py

DescriÃ§Ã£o:

LÃª arquivo como DataFrame

Limpa e separa palavras em linhas individuais

Agrupa por palavra e conta ocorrÃªncias

Ordena do mais frequente para o menos frequente

Salva resultado em CSV e mostra no terminal

ExecuÃ§Ã£o:

python wordcount_dataframe.py


Exemplo de saÃ­da no terminal:

palavra	count
dados	4
python	3
spark	2
aprendizado	1

SaÃ­da: salva na pasta saida_df/contagem_palavras em CSV.

3ï¸âƒ£ WordCount em Streaming

Arquivo: wordcount_streaming.py

DescriÃ§Ã£o:

Monitora continuamente a pasta stream_input

Processa arquivos de texto adicionados em tempo real

Limpa e separa palavras, conta frequÃªncias

Mostra resultados no console continuamente

ExecuÃ§Ã£o:

python wordcount_streaming.py


Como testar:

Enquanto o script estiver rodando, adicione arquivos .txt na pasta stream_input.

A contagem de palavras serÃ¡ atualizada automaticamente no console.

ğŸ”„ Estrutura de processamento
Abordagem	Fluxo de processamento
RDD	textFile â†’ flatMap â†’ map â†’ reduceByKey â†’ collect/save
DataFrame	read.text â†’ regexp_replace â†’ split â†’ explode â†’ groupBy â†’ count â†’ write
Streaming	readStream.text â†’ regexp_replace â†’ split â†’ explode â†’ groupBy â†’ count â†’ writeStream
ğŸ’¡ Dicas

Evite collect() em arquivos grandes; use write para salvar resultados.

Use expressÃµes regulares para limpar pontuaÃ§Ã£o e caracteres especiais.

Combine DataFrame + Streaming para pipelines mais eficientes.

Pode salvar saÃ­da de streaming em CSV, Parquet ou enviar para Kafka.

ğŸ“ˆ Exemplo Visual de Pipeline (DataFrame/Streaming)
Arquivo de Texto
      â”‚
      â–¼
  Spark DataFrame
      â”‚
  Limpeza e NormalizaÃ§Ã£o
      â”‚
   Split/Explode
      â”‚
   Agrupamento por Palavra
      â”‚
   Contagem de FrequÃªncia
      â”‚
   SaÃ­da (Console / Arquivo / Kafka)
