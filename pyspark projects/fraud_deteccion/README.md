ğŸ’³ DetecÃ§Ã£o de Fraudes com PySpark & MLlib








ğŸš€ Projeto de DetecÃ§Ã£o de Fraudes em larga escala utilizando PySpark + MLlib, com pipeline completo de ingestÃ£o, feature engineering, modelagem e avaliaÃ§Ã£o.

ğŸ§  VisÃ£o Geral

Fraudes financeiras representam bilhÃµes de dÃ³lares em prejuÃ­zo por ano.
Este projeto demonstra como construir um sistema escalÃ¡vel de detecÃ§Ã£o de fraudes com PySpark, capaz de processar milhÃµes de transaÃ§Ãµes com alta eficiÃªncia.

ğŸ“Œ Objetivos principais:

Criar e processar um dataset de transaÃ§Ãµes simuladas.

Gerar features relevantes para detecÃ§Ã£o de fraudes.

Treinar modelos de Machine Learning distribuÃ­do com MLlib.

Avaliar desempenho usando AUC ROC e selecionar o melhor modelo.

ğŸ§± Arquitetura do Projeto
fraud_detection_pyspark/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ transactions.csv         # Dataset sintÃ©tico (200.000 linhas)
â”‚
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ fraud_detection.log      # Logs de execuÃ§Ã£o
â”‚
â”œâ”€â”€ models/                      # Modelos salvos (.model)
â”‚
â”œâ”€â”€ generate_dataset.py          # GeraÃ§Ã£o do dataset de exemplo
â”œâ”€â”€ pipeline_basic.py            # Pipeline simples
â”œâ”€â”€ pipeline_advanced.py         # Pipeline com tuning
â”œâ”€â”€ pipeline_balanced.py         # Pipeline com oversampling
â”œâ”€â”€ pipeline_professional.py     # Pipeline completo com CV
â””â”€â”€ README.md

ğŸ“Š Dataset SintÃ©tico

O dataset contÃ©m 200.000 transaÃ§Ãµes financeiras com 2% de fraudes.

Coluna	Tipo	DescriÃ§Ã£o
transaction_id	int	ID Ãºnico da transaÃ§Ã£o
amount	float	Valor da transaÃ§Ã£o
time	string	Timestamp da transaÃ§Ã£o
merchant_type	string	Tipo de comerciante
is_fraud	int	1 = fraude / 0 = legÃ­tima

ğŸ“ Gerado automaticamente pelo script:

python generate_dataset.py

âš™ï¸ ExecuÃ§Ã£o
ğŸ”¹ InstalaÃ§Ã£o de dependÃªncias
pip install pyspark

ğŸ”¹ GeraÃ§Ã£o do dataset
python generate_dataset.py

ğŸ”¹ Rodar o pipeline profissional
spark-submit pipeline_professional.py

ğŸ¤– Modelos Treinados
Modelo	Tipo	MÃ©trica Avaliada	AUC ROC	ObservaÃ§Ãµes
Logistic Regression	Linear	ClassificaÃ§Ã£o BinÃ¡ria	0.93	Melhor equilÃ­brio entre precisÃ£o e recall
Decision Tree	Ãrvores	ClassificaÃ§Ã£o	0.88	Boa interpretabilidade
Random Forest	Ensemble	ClassificaÃ§Ã£o	0.95	Excelente performance, porÃ©m mais pesado
GBTClassifier	Ensemble Boosted	ClassificaÃ§Ã£o	0.97	Melhor desempenho geral

ğŸ“ˆ Melhor modelo: GBTClassifier (Gradient Boosted Trees)

ğŸ§© Componentes do Pipeline

Feature Engineering

IndexaÃ§Ã£o e vetorizaÃ§Ã£o de variÃ¡veis categÃ³ricas (merchant_type)

NormalizaÃ§Ã£o de valores (amount)

CriaÃ§Ã£o de vetor de features (VectorAssembler)

Treinamento de Modelo

Logistic Regression, Decision Tree, Random Forest, GBT

AvaliaÃ§Ã£o

BinaryClassificationEvaluator(metricName="areaUnderROC")

PersistÃªncia

Salvamento do modelo no diretÃ³rio /models

Leitura para produÃ§Ã£o com PipelineModel.load()

ğŸ“ˆ Exemplo de SaÃ­da no Log
[INFO] Iniciando pipeline de detecÃ§Ã£o de fraudes...
[INFO] Dados carregados: 200000 registros.
[INFO] Treinando modelo: Logistic Regression
[INFO] AUC = 0.932
[INFO] Melhor modelo: GBTClassifier com AUC = 0.971
[INFO] Modelo salvo em: models/fraud_detection_GBTClassifier_pro

ğŸ§° Tecnologias
Tecnologia	Uso
PySpark	Processamento distribuÃ­do e ML
MLlib	Treinamento e avaliaÃ§Ã£o de modelos
Spark SQL	ManipulaÃ§Ã£o de dados
Python	Scripts e orquestraÃ§Ã£o
CSV / Parquet	Armazenamento de dados
ğŸ”¬ PrÃ³ximos Passos

 Adicionar detecÃ§Ã£o de anomalias em tempo real (Streaming com Kafka)

 Implementar explainability (SHAP/LIME)

 Deploy do modelo com MLflow

 Dashboard com Grafana/Streamlit

ğŸ§‘â€ğŸ’» Autor

Sthefany Spina
ğŸ’¼ Projetos em Big Data, Spark e Machine Learning
ğŸ“§ Contato: sthefanyspina.dev@gmail.com

ğŸªª LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT.
Sinta-se livre para usar, modificar e compartilhar!